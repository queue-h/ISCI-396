{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86689d43-d825-4ce9-acec-fea7796d20db",
   "metadata": {},
   "source": [
    "# Problem Set 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8ec0a2-7e62-4071-95d8-d8f7538d3f72",
   "metadata": {},
   "source": [
    "## Problem 1: Galaxy Photometric Redshifts (6 points)\n",
    "\n",
    "Let us return to an example from cosmology. Many of the galaxies we observe with telescopes are millions of light years away. Because the Universe has expanded since the light of a galaxy was emitted, its light is shifted towards longer wavelengths, i.e., redder parts of the electromagnetic spectrum. This effect, which is called redshift, can be measured precisely with spectroscopy. However, spectroscopy is time-consuming and challenging for a large number of galaxies. Thus, a common problem in astronomy is trying to estimate the redshift of a galaxy by looking only at its flux or intensity in different parts, so-called bands, of the electromagnetic spectrum. Redshifts estimated this way are called photometric redshifts.\n",
    "\n",
    "The file `Problem_Set_4_Redshifts.csv` contains the following data.\n",
    "* `<BAND>_FLUX`: Fluxes in different bands. This is what will be used for training. Note that the data has been cleaned, and galaxies with missing fluxes have been removed.\n",
    "* `Z_PHOT`: This is the redshift estimated from a state-of-the-art photometric redshift code, [LePHARE](https://lephare.readthedocs.io/en/latest/). You should **not** use this during training or validation. It's simply another estimate to compare against.\n",
    "* `Z_SPEC`: These are spectroscopic redshifts $z_\\mathrm{spec}$ measured from the Dark Energy Spectroscopic Instrument (DESI).\n",
    "\n",
    "(For those interested, fluxes and photometric redshifts come from the [COSMOS2020 catalog](https://cosmos2020.calet.org/). The spectroscopic redshifts are available [here](https://data.desi.lbl.gov/public/papers/c3/cosmos-xmmlss/). The script `make_problem_set_4.py` \"reduces\" the publicly available data sets to `Problem_Set_4_Redshifts.csv`.)\n",
    "\n",
    "(a) Make a histogram of the spectroscopic redshifts, $z_\\mathrm{spec}$. Additionally, compute the $R^2$ score of a simple linear model as a baseline to compare against.\n",
    "\n",
    "(b) Use a random forest to predict the spectroscopic redshift from the measured fluxes. Perform a $k$-fold cross-validation with $k=10$ to optimize hyperparameters based on the $R^2$ score. Include (+/- 1 standard deviation) error bars derived from the scatter between different folds. To keep the compute time reasonable, limit the number of trees in the random forest to $30$. How does the score of the random forest compare against the linear model? I'm not grading you on having found the absolute best hyperparameters as long as the cross-validation search is reasonable, that is, testing a few values for $3$ or $4$ hyperparameters within reasonable ranges. (Tip: You probably want to use `n_jobs=-1` in `sklearn.ensemble.RandomForestRegressor` to make the random forest use as many CPU cores as possible.)\n",
    "\n",
    "(c) Compute the cross-validated $R^2$ training curve for the best-performing hyperparameters with with the number of training samples $n$ going from $1000$ to $10000$. As for (b), please include error bars. Does this curve indicate significant overfitting? Would our random forest redshifts benefit meaningfully from more training data?\n",
    "\n",
    "(d) In astronomy, we are often interested in the catastrophic outlier rate $\\eta$ of redshifts. This rate is defined as the fraction of photometric redshifts $\\hat z$ for which $|\\hat z - z_\\mathrm{spec}| > 0.15 (1 + z_\\mathrm{spec})$. Thus, another \"score\" we are interested in is $1 - \\eta$, the fraction of redshifts that are not catastrophic outliers. Plot the learning curve for the cross-validated $1 - \\eta$ score and indicate the catastrophic outlier rate of the LePHARE photometric redshifts in the same plot. (Hint: `sklearn.model_selection` can take a custom score function via the `scoring` keyword argument. More information can be found [here](https://scikit-learn.org/stable/modules/model_evaluation.html#custom-scorer-objects-from-scratch).)\n",
    "\n",
    "(e) Visualize the feature importance in the random forest. What does this indicate about the importance of different photometric bands?"
   ]
  },
  {
   "cell_type": "code",
   "id": "658b48be-51df-4082-a690-1cca5df96721",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T02:42:47.838897Z",
     "start_time": "2025-10-09T02:42:47.681282Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "df = pd.read_csv(\"Problem_Set_4_Redshifts.csv\")\n",
    "y = df[\"Z_SPEC\"]\n",
    "X = df.iloc[:, :35] # all fluxes\n",
    "y_est = df[\"Z_PHOT\"]\n",
    "flux_names = X.columns\n",
    "\n",
    "def a():\n",
    "    plt.yscale(\"log\")\n",
    "    plt.hist(df[\"Z_SPEC\"], bins = 50)\n",
    "    plt.title(\"Spectroscopic Redshift Distribution\")\n",
    "    plt.xlabel(\"Z Spec\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()\n",
    "\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "    y_pred = reg.predict(X)\n",
    "    linear_r2 = metrics.r2_score(y_est, y_pred)\n",
    "    print(\"Linear Regression R2 Score:\", linear_r2)\n",
    "\n",
    "#### unsure about what param_grid should be\n",
    "def b():\n",
    "    k_num = 10\n",
    "    kfold = model_selection.KFold(n_splits=k_num, shuffle=True)\n",
    "    random_forest = RandomForestRegressor(n_estimators=30, n_jobs=-1)\n",
    "    model = model_selection.GridSearchCV(random_forest, list(flux_names), cv = kfold, scoring = \"r2\").fit(X, y)\n",
    "    forest_r2 = model.cv_results[\"mean_test_score\"]\n",
    "    print(\"Random Forest R2 Score:\", forest_r2)\n",
    "\n",
    "b()"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Parameter grid is not a dict ('CFHT_u_FLUX')",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[49]\u001B[39m\u001B[32m, line 36\u001B[39m\n\u001B[32m     33\u001B[39m     forest_r2 = model.cv_results[\u001B[33m\"\u001B[39m\u001B[33mmean_test_score\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m     34\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mRandom Forest R2 Score:\u001B[39m\u001B[33m\"\u001B[39m, forest_r2)\n\u001B[32m---> \u001B[39m\u001B[32m36\u001B[39m \u001B[43mb\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[49]\u001B[39m\u001B[32m, line 32\u001B[39m, in \u001B[36mb\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     30\u001B[39m kfold = model_selection.KFold(n_splits=k_num, shuffle=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m     31\u001B[39m random_forest = RandomForestRegressor(n_estimators=\u001B[32m30\u001B[39m, n_jobs=-\u001B[32m1\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m32\u001B[39m model = \u001B[43mmodel_selection\u001B[49m\u001B[43m.\u001B[49m\u001B[43mGridSearchCV\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrandom_forest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mflux_names\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mkfold\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscoring\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mr2\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     33\u001B[39m forest_r2 = model.cv_results[\u001B[33m\"\u001B[39m\u001B[33mmean_test_score\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m     34\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mRandom Forest R2 Score:\u001B[39m\u001B[33m\"\u001B[39m, forest_r2)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/GitHub/School/ISCI-396/.venv/lib/python3.13/site-packages/sklearn/base.py:1365\u001B[39m, in \u001B[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(estimator, *args, **kwargs)\u001B[39m\n\u001B[32m   1358\u001B[39m     estimator._validate_params()\n\u001B[32m   1360\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m   1361\u001B[39m     skip_parameter_validation=(\n\u001B[32m   1362\u001B[39m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m   1363\u001B[39m     )\n\u001B[32m   1364\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1365\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/GitHub/School/ISCI-396/.venv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1051\u001B[39m, in \u001B[36mBaseSearchCV.fit\u001B[39m\u001B[34m(self, X, y, **params)\u001B[39m\n\u001B[32m   1045\u001B[39m     results = \u001B[38;5;28mself\u001B[39m._format_results(\n\u001B[32m   1046\u001B[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[32m   1047\u001B[39m     )\n\u001B[32m   1049\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[32m-> \u001B[39m\u001B[32m1051\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1053\u001B[39m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[32m   1054\u001B[39m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[32m   1055\u001B[39m first_test_score = all_out[\u001B[32m0\u001B[39m][\u001B[33m\"\u001B[39m\u001B[33mtest_scores\u001B[39m\u001B[33m\"\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/GitHub/School/ISCI-396/.venv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1605\u001B[39m, in \u001B[36mGridSearchCV._run_search\u001B[39m\u001B[34m(self, evaluate_candidates)\u001B[39m\n\u001B[32m   1603\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[32m   1604\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1605\u001B[39m     evaluate_candidates(\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/GitHub/School/ISCI-396/.venv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:119\u001B[39m, in \u001B[36mParameterGrid.__init__\u001B[39m\u001B[34m(self, param_grid)\u001B[39m\n\u001B[32m    117\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m grid \u001B[38;5;129;01min\u001B[39;00m param_grid:\n\u001B[32m    118\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(grid, \u001B[38;5;28mdict\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m119\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mParameter grid is not a dict (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mgrid\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[33m)\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    120\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m grid.items():\n\u001B[32m    121\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value, np.ndarray) \u001B[38;5;129;01mand\u001B[39;00m value.ndim > \u001B[32m1\u001B[39m:\n",
      "\u001B[31mTypeError\u001B[39m: Parameter grid is not a dict ('CFHT_u_FLUX')"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "30f732b7ff09aea1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
